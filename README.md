# tpch_dbgen_zipf_skew

TPC-H datagen relies on uniform distributions to an extensive degree. The values of dimension columns
are generated uniformly random within a range. The numbers of lines in LINEITEM that have a given 
ORDERKEY is also chosen uniformly at random and so are the number of suppliers (SUPPKEY) per part 
(PARTKEY).  The goal of this change is to add skew, specifically zipfian skew, to the extent possible.

Zipfian skew is such that the frequency with which a value at rank k occurs is proportional to 1/k^\alpha.
For example, if \alpha is 2, then by rank the frequencies are proportional to: 1, 0.25, 0.11, 0.125, ...

There are many ways to obtain zipf distributed values.  We seek a method that allows for // execution.
Specifically, when many tasks execute in parallel, the output dataset should match dataset that would 
be generated by a single task.

To that end, our method is as follows:
1) Each task pre-computes (in a pseudo-random way) the values at the top N ranks. 
(NumTopRanksPerStream = 1000) The tasks also compute the probability with which to pick each of 
these ranks as well as the residual probability.

2) To pick a zipf distributed random value, each task picks either from the top N ranks or, with the 
residual probability, uniformly at random from a value that is not in the top N ranks.  The task tries
at most 5 times though to look for a value that is not in the top N.

3) We edit the ADVANCE_SEED function so that each task can roll the state of its seeds ahead 
(speed_seed.c) by the number of rows that would be generated by the tasks preceding it. We also edit the 
"boundary" values used by the row_stop function so that each seed advances by a fixed amount per row 
regardless of what may be necessary to generate that row.

4) Note that the datagen uses different seeds; roughly speaking one per column. However, some seeds 
are used to generate values from different ranges (nLow and nHigh). This interferes with step 1 above 
because picking the pre-computed values requires a fixed range. We use two different strategies to account
for this concern. (a) We add more seeds one per RANDOM call. We do this for all the comment column; where 
the offset and length are picked using different seeds. (b) We only use zipf distribution for some of the
RANDOM calls but not all; such as in gen_phone where the last four digits are generated uniformly at random. 
We do this to reduce the number of seeds without adversely affecting the skew of the column.


The above process does not generate proper zipf distribution. In particular, the values corresponding
to "residual probability" are generated uniformly at random in the range and then checked to not match 
with the values that have already been picked to represent the top N ranks. Also, if five consecutive
attempts to find a new value fail, we just use the fifth chosen value.  The reason to do this is clear:
we want to use a bounded size manifest and we want to make no more than a small (and bounded) number 
of random calls.  We analyze the properties of this method in the following.

* Case of number of distinct values in the range or number of tuples being smaller than N:
This happens for a fair number of columns in TPC-H. For such columns, the method above generates proper
zipfian distribution.

* Dependence on the zipf scale factor:
The larger the scale factor the faster the probability decays. Thus, closely approximating a zipfian
distribution can require maintaining more ranks when the zipf scale factor is smaller. The table below
shows, for different zipf scale factors, the fraction of the total probability that is contributed by the 
top N ranks:

	Zipf Scale Factor	N= 100		N= 1000		N= 10000
	2.0					99.994
	1.5					95.73		99.996		
	1.0					52.90		76.47		99.999
	0.5					 8.31		31.12		99.995

The memory footprint increases with N (but by a rather small factor). 
The computation cost also increases with N but also by a small factor.

We recommend setting the NumTopRanksPerStream constant in dss.h appropriately.
